{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ca6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf9c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11fc96b",
   "metadata": {},
   "source": [
    "# Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87eb11f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/08 19:41:16 WARN Utils: Your hostname, myThinkPad resolves to a loopback address: 127.0.1.1; using 192.168.250.222 instead (on interface wlp3s0)\n",
      "23/07/08 19:41:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/08 19:41:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/07/08 19:41:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "                     .appName(\"MLLib\")\n",
    "                     .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d352e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f583ee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Read the raw Restaurant csv data--------\n",
      "+----------------------+---------------------+-----------+-------+---------+\n",
      "|Miscellaneous_Expenses|Food_Innovation_Spend|Advertising|City   |Profit   |\n",
      "+----------------------+---------------------+-----------+-------+---------+\n",
      "|138671.8              |167497.2             |475918.1   |Chicago|202443.83|\n",
      "|153151.59             |164745.7             |448032.53  |Mumbai |201974.06|\n",
      "|102919.55             |155589.51            |412068.54  |Tokyo  |201232.39|\n",
      "|120445.85             |146520.41            |387333.62  |Chicago|193083.99|\n",
      "|93165.77              |144255.34            |370302.42  |Tokyo  |176369.94|\n",
      "+----------------------+---------------------+-----------+-------+---------+\n",
      "\n",
      "root\n",
      " |-- Miscellaneous_Expenses: double (nullable = true)\n",
      " |-- Food_Innovation_Spend: double (nullable = true)\n",
      " |-- Advertising: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'Data_Science_Bootcamp/Regression_Algorithms/Multiple_Linear_Regression/Restaurant_Profit_Data.csv'\n",
    "\n",
    "\n",
    "# Read in the student data\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "print('-----Read the raw Restaurant csv data--------')\n",
    "df.limit(5).show(truncate=False)\n",
    "df.printSchema()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f397a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e51dcb4",
   "metadata": {},
   "source": [
    "# Create a Feature array by omitting the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7821b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time_to_Study']\n",
      "VectorAssembler_c5443a743cbc\n",
      "***********************************************\n",
      "+-------------+------+--------+\n",
      "|Time_to_Study|Grades|features|\n",
      "+-------------+------+--------+\n",
      "|            1|   1.5|   [1.0]|\n",
      "|            5|   2.7|   [5.0]|\n",
      "|            7|   3.1|   [7.0]|\n",
      "|            3|   2.1|   [3.0]|\n",
      "|            2|   1.8|   [2.0]|\n",
      "|            9|   3.9|   [9.0]|\n",
      "|            6|   2.9|   [6.0]|\n",
      "|           12|   4.5|  [12.0]|\n",
      "|           11|   4.3|  [11.0]|\n",
      "|            2|   1.8|   [2.0]|\n",
      "|            4|   2.4|   [4.0]|\n",
      "|            8|   3.5|   [8.0]|\n",
      "|           13|   4.8|  [13.0]|\n",
      "|            9|   3.9|   [9.0]|\n",
      "|           14|   5.0|  [14.0]|\n",
      "|           10|   4.1|  [10.0]|\n",
      "|            6|   2.9|   [6.0]|\n",
      "|           12|   4.5|  [12.0]|\n",
      "|            1|   1.5|   [1.0]|\n",
      "|            4|   2.4|   [4.0]|\n",
      "+-------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_cols = df.columns[:-1] \n",
    "print(feature_cols)\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vect_assembler = VectorAssembler(inputCols=feature_cols,outputCol=\"features\")\n",
    "print(vect_assembler)\n",
    "print('***********************************************')\n",
    "#Utilize Assembler created above in order to add the feature column\n",
    "data_w_features = vect_assembler.transform(df)\n",
    "data_w_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f3777",
   "metadata": {},
   "source": [
    "Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "864dd3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------+\n",
      "|Time_to_Study|Grades|features|\n",
      "+-------------+------+--------+\n",
      "|            1|   1.5|   [1.0]|\n",
      "|            5|   2.7|   [5.0]|\n",
      "|            7|   3.1|   [7.0]|\n",
      "|            3|   2.1|   [3.0]|\n",
      "|            2|   1.8|   [2.0]|\n",
      "+-------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Display the data having additional column named features. Had it been multiple linear regression problem, \n",
    "## you could see all the independent variable values combined in one list\n",
    "data_w_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "221fd293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|features|Grades|\n",
      "+--------+------+\n",
      "|   [1.0]|   1.5|\n",
      "|   [5.0]|   2.7|\n",
      "|   [7.0]|   3.1|\n",
      "|   [3.0]|   2.1|\n",
      "|   [2.0]|   1.8|\n",
      "|   [9.0]|   3.9|\n",
      "|   [6.0]|   2.9|\n",
      "|  [12.0]|   4.5|\n",
      "|  [11.0]|   4.3|\n",
      "|   [2.0]|   1.8|\n",
      "|   [4.0]|   2.4|\n",
      "|   [8.0]|   3.5|\n",
      "|  [13.0]|   4.8|\n",
      "|   [9.0]|   3.9|\n",
      "|  [14.0]|   5.0|\n",
      "|  [10.0]|   4.1|\n",
      "|   [6.0]|   2.9|\n",
      "|  [12.0]|   4.5|\n",
      "|   [1.0]|   1.5|\n",
      "|   [4.0]|   2.4|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select only Features and Label from previous dataset as we need these two entities for building machine learning model\n",
    "\n",
    "finalized_data = data_w_features.select(\"features\",\"Grades\")\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14210be",
   "metadata": {},
   "source": [
    "# Split the data into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c50ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Grades|\n",
      "+-------+------------------+\n",
      "|  count|                41|\n",
      "|   mean|3.0634146341463415|\n",
      "| stddev|1.0627219997631026|\n",
      "|    min|               1.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|            Grades|\n",
      "+-------+------------------+\n",
      "|  count|                 9|\n",
      "|   mean|3.9444444444444446|\n",
      "| stddev|1.0548828265631105|\n",
      "|    min|               2.7|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the data into training and test model with 70% obs. going in training and 30% in testing\n",
    "train_dataset, test_dataset = finalized_data.randomSplit([0.8, 0.2])\n",
    "train_dataset.describe().show()\n",
    "test_dataset.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7fe289",
   "metadata": {},
   "source": [
    "# Perform Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c976a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/08 19:28:19 WARN Instrumentation: [1680c1a9] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------------+\n",
      "|features|Grades|        prediction|\n",
      "+--------+------+------------------+\n",
      "|   [5.0]|   2.7| 2.645892561983471|\n",
      "|   [5.0]|   2.7| 2.645892561983471|\n",
      "|   [6.0]|   2.9|2.9219958677685947|\n",
      "|   [7.0]|   3.1| 3.198099173553719|\n",
      "|  [12.0]|   4.5| 4.578615702479339|\n",
      "|  [13.0]|   4.8| 4.854719008264462|\n",
      "|  [13.0]|   4.8| 4.854719008264462|\n",
      "|  [14.0]|   5.0|5.1308223140495866|\n",
      "|  [14.0]|   5.0|5.1308223140495866|\n",
      "+--------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import Linear Regression class called LinearRegression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "#Create the Linear Regression object named having feature column as features and Label column as Time_to_Study\n",
    "LinReg = LinearRegression(featuresCol=\"features\", labelCol=\"Grades\")\n",
    "\n",
    "#Train the model on the training using fit() method.\n",
    "model = LinReg.fit(train_dataset)\n",
    "\n",
    "#Predict the Grades using the evulate method\n",
    "pred = model.evaluate(test_dataset)\n",
    "\n",
    "#Show the predicted Grade values along side actual Grade values\n",
    "pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938a9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735d8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out coefficient value\n",
    "coefficient = model.coefficients\n",
    "print (\"The coefficient of the model is : %a\" %coefficient)\n",
    "\n",
    "#Find out intercept Value\n",
    "intercept = model.intercept\n",
    "print (\"The Intercept of the model is : %f\" %intercept)\n",
    "\n",
    "#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean Square Error(RMSE) and R-Square\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluation = RegressionEvaluator(labelCol=\"Grades\", predictionCol=\"prediction\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f053018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321cc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3edf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f40606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952263c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
